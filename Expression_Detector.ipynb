{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "#Reading pixel values of images in the form of csv as a dataframe\n",
    "data=pd.read_csv('C://Users//Jeshwanth//Desktop//all//fer2013//fer2013.csv')\n",
    "#Seperating emotion and pixels values as Y_train and X_train respectively\n",
    "X_train,Y_train=data['pixels'],data['emotion']\n",
    "X_train=X_train.as_matrix()\n",
    "Y_train=Y_train.as_matrix()\n",
    "#Splitting pixls in the form of strings to lists\n",
    "for i in range(X_train.size):\n",
    "    X_train[i]=[int(s) for s in X_train[i].split(' ')]\n",
    "#Converting list to np.array\n",
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "#Converting each of the rows in X_train from strings to lists\n",
    "for i in range(X_train.size):\n",
    "    X_train[i]=np.array(X_train[i])\n",
    "#Splitting X_train,Y_train  into (X_Train,X_test,X_private),(Y_Train,Y_test,Y_private)\n",
    "X_Train=X_train[0:28710]\n",
    "X_test=X_train[28710:32299]\n",
    "X_private=X_train[32299:]\n",
    "Y_Train=Y_train[0:28710]\n",
    "Y_test=Y_train[28710:32299]\n",
    "Y_private=Y_train[32299:]\n",
    "#Reshaping the pixels into dimensions of images\n",
    "for i in range(X_Train.size):\n",
    "    X_train[i]=X_Train[i].reshape(48,48,1)\n",
    "for i in range(X_test.size):\n",
    "    X_test[i]=X_test[i].reshape(48,48,1)\n",
    "for i in range(X_private.size):\n",
    "    X_private[i]=X_private[i].reshape(48,48,1)\n",
    "#One-hot encoding dependent variables\n",
    "from keras.utils import to_categorical\n",
    "Y_Train=to_categorical(Y_Train)\n",
    "Y_test=to_categorical(Y_test)\n",
    "Y_private=to_categorical(Y_private) \n",
    "#Data_augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "data_gen=ImageDataGenerator(rotation_range=20,\n",
    "        width_shift_range=0.02,\n",
    "        height_shift_range=0.02,\n",
    "        horizontal_flip=True)\n",
    "#Building the model and executing \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Dense,Flatten,MaxPooling2D,Dropout\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(48,48,1)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=2,padding='valid'))\n",
    "model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=2,padding='valid'))\n",
    "model.add(Conv2D(128,kernel_size=3,activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(MaxPooling2D(pool_size=2,padding='valid'))\n",
    "model.add(Conv2D(256,kernel_size=3,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=2,padding='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(7,activation='softmax'))\n",
    "from keras import optimizers\n",
    "opt=optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer=opt,metrics=['accuracy'],loss='categorical_crossentropy')\n",
    "X_Train=np.concatenate([i for i in X_Train])\n",
    "X_test=np.concatenate([i for i in X_test])\n",
    "X_private=np.concatenate([i for i in X_private])\n",
    "X_Train=X_Train.reshape(28710,48,48,1)\n",
    "X_test=X_test.reshape(3589,48,48,1)\n",
    "X_private=X_private.reshape(3588,48,48,1)\n",
    "model.fit_generator(data_gen.flow(X_Train, Y_Train),steps_per_epoch=len(X_Train)//32, validation_data=(X_test, Y_test), epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwanth\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "edfc0dfe2ce146a7fd1a34904e7d737da510baf0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assing a no. to each of the expressions in a dictionary\n",
    "em={0:\"Angry\", 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise',6:'Neutral'}\n",
    "#Loading saved model\n",
    "loaded_model=load_model('ema63.h5')\n",
    "#Process to take input from webcam and detect the expression\n",
    "import cv2\n",
    "faceCascade = cv2.CascadeClassifier('C:\\\\Users\\\\Jeshwanth\\\\Desktop\\\\all\\\\haarcascade_frontalface_alt.xml')\n",
    "# grab the reference to the webcam\n",
    "vs = cv2.VideoCapture(0) #0 is webcam\n",
    "\n",
    "# keep looping\n",
    "while True:\n",
    " # grab the current frame\n",
    "    ret, frame = vs.read()\n",
    "    #print('Done')\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY);\n",
    "    faces = faceCascade.detectMultiScale(gray)\n",
    "    #print(len(faces))\n",
    "    if(len(faces)>0):\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255,0,0), 2)\n",
    "            temp=gray[y:y+h,x:x+w]\n",
    "            img=cv2.resize(temp,(48,48))\n",
    "            image=img.reshape(1,48,48,1)\n",
    "            value=loaded_model.predict(image)\n",
    "            font= cv2.FONT_HERSHEY_SIMPLEX\n",
    "            bottomLeftCornerOfText = ((2*x+w)//2,y+h+1)\n",
    "            fontScale= 1\n",
    "            fontColor= (255,255,255)\n",
    "            lineType = 2\n",
    "            cv2.putText(frame,em[np.argmax(value)], bottomLeftCornerOfText, font, fontScale,fontColor,lineType)\n",
    "            # show the frame to our screen\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    #print(em[np.argmax(value)])\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "vs.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6401895206243032\n"
     ]
    }
   ],
   "source": [
    "#Testing accuracy on private test data\n",
    "x=loaded_model.predict(X_private)\n",
    "z=0\n",
    "#print(x.size,Y_private.size)\n",
    "for i in range(x.shape[0]):\n",
    "    ze=np.argmax(Y_private[i])-np.argmax(x[i])\n",
    "    if(ze==0):\n",
    "        z=z+1\n",
    "print(z/x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
